
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>

  <title>Xinhong Ma's Homepage</title>

  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="description" content="Xinhong Ma is currently a researcher at Huawei Noah's Ark Lab">
  <meta name="keywords" content="Xinhong Ma, 马昕宏, maxinhong, Xinhong, Ma, Deep Learning, Huawei, CASIA, UCAS, Computer, Vision">
  <meta name="author" content="Xinhong Ma" />

  <link rel="stylesheet" href="w3.css">

  <style>
  .w3-sidebar a {font-family: "Roboto", sans-serif}
  body,h1,h2,h3,h4,h5,h6,.w3-wide {font-family: "Montserrat", sans-serif;}
  </style>

  <link rel="icon" type="image/png" href="images/icons.png">
  <!--
  <script src="jquery.min.js"></script>
  <script>
  $(document).ready(function(){
    // Add smooth scrolling to all links
    $("a").on('click', function(event) {
      // Make sure this.hash has a value before overriding default behavior
      if (this.hash !== "") {
        // Prevent default anchor click behavior
        event.preventDefault();
        // Store hash
        var hash = this.hash;
        // Using jQuery's animate() method to add smooth page scroll
        // The optional number (800) specifies the number of milliseconds it takes to scroll to the specified area
        $('html, body').animate({
          scrollTop: $(hash).offset().top
        }, 800, function(){
          // Add hash (#) to URL when done scrolling (default click behavior)
          window.location.hash = hash;
        });
      } // End if
    });
  });
  </script>
  //-->

</head>


<body class="w3-content" style="max-width:1000px">

<!-- Sidebar/menu -->
<nav class="w3-sidebar w3-bar-block w3-black w3-collapse w3-top w3-right" style="z-index:3;width:150px" id="mySidebar">
  <div class="w3-container w3-display-container w3-padding-16">
    <h3><b>XINHONG</b></h3>
  </div>
  <div class="w3-padding-64 w3-text-light-grey w3-large" style="font-weight:bold">
    <a href="#home" class="w3-bar-item w3-button">Home</a>
    <!-- <a href="#news" class="w3-bar-item w3-button">News</a>
    <a href="#projects" class="w3-bar-item w3-button">Projects</a>
    <a href="#talks" class="w3-bar-item w3-button">Talks</a> -->
    <a href="#publications" class="w3-bar-item w3-button">Research</a>
    <a href="#service" class="w3-bar-item w3-button">Services</a>
    <a href="#award" class="w3-bar-item w3-button">Awards</a>
  </div>
</nav>

<!-- Top menu on small screens -->
<header class="w3-bar w3-top w3-hide-large w3-black w3-xlarge">
  <div class="w3-bar-item w3-padding-24">XINHONG</div>
  <a href="javascript:void(0)" class="w3-bar-item w3-button w3-padding-24 w3-right"  style="font-stretch: extra-expanded;" onclick="w3_open()"><b>≡</b></a>
  </div>
</header>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large" onclick="w3_close()" style="cursor:pointer" title="close side menu" id="myOverlay"></div>

<!-- !PAGE CONTENT! -->
<div class="w3-main" style="margin-left:150px">

  <!-- Push down content on small screens -->
  <div class="w3-hide-large" style="margin-top:83px"></div>

<!-- The Home Section -->
    <div class="w3-container w3-center w3-padding-32" id="home">
      <img style="width: 50%;max-width: 720px" alt="profile photo" src="images/xinhong.jpg">
      <h1>Xinhong Ma (马昕宏)</h1>
        <p class="w3-justify" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;max-width:600px">
          I am currently a Researcher in 
          <a href="https://www.noahlab.com.hk/">Huawei Noah's Ark Lab</a>, 
          where I work on deep learning, transfer learning, and computer vision, etc. 
          I received the Ph.D. degree in 2022 from the Institute of Automation, Chinese Academy of Sciences (CASIA), 
          where I was co-advised by Professor <a href="https://scholar.google.com/citations?user=hI9NRDkAAAAJ">Changsheng Xu</a>,
          Professor <a href="http://staff.ustc.edu.cn/~tzzhang/">Tianzhu Zhang</a>,
          Associate Professor <a href="https://yangxs.ac.cn/home">Xiaoshan Yang</a>,
          and Assistant Professor <a href="https://scholar.google.com/citations?hl=en&user=y1nOY24AAAAJ">Junyu Gao</a>. 
          I obtained my BSc degree in Automation, <a href="https://english.bit.edu.cn//">Beijing Institute of Technology</a>.
        </p>
        <p class="w3-center">
          <a href="mailto:maxinhong@huawei.com">Gmail (Primary)</a> &nbsp/&nbsp
          <a href="mailto:maxinhong@huawei.com">Email</a> &nbsp/&nbsp
          <a href="https://github.com/stefanxinhong">Github</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?user=a44XUMQAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://dblp.org/pid/248/0802.html"> DBLP </a>
        </p>
        </tbody></table>
  </div>

<!-- The News Section -->
  <!-- <div class="w3-container w3-light-grey w3-padding-32" id="news">
   <h2>News</h2>
      <p><li> 05/2023, I will give a talk about Multimodal Learning at <a href="http://valser.org/2023/#/workshopde?id=11">VALSE 2023 workshop</a>.</li></p>
  </div> -->

<!-- The Projects Section -->
  <!-- <div class="w3-container w3-padding-32" id="projects">
    <h2>Recent Projects</h2>
	      <h4><li>The Vanilla Neural Architecture for the 2020s</li></h4>
        <img style="width:96%;" src="images/VanillaNet.png"> 
        <p class="w3-justify">
        <a style="color: #447ec9" href="https://github.com/huawei-noah/VanillaNet">Project Page</a> | <a style="color: #447ec9" href="https://arxiv.org/pdf/2101.10015.pdf">Hardware Implementation</a>
        </p>
        <p class="w3-justify">
        VanillaNet is remarkable! The concept was born from embracing the "less is more" philosophy in computer vision. It's elegantly designed by avoiding intricate depth and operations, such as self-attention, making it remarkably powerful yet concise. The 6-layer VanillaNet surpasses ResNet-34, and the 13-layer variant achieves about 83% Top-1 accuracy, outpacing the performance of networks with hundreds of layers, and revealing exceptional hardware efficiency advantages.
        </p> 
  </div> -->
  
  <!-- The Talks Section -->
  <!-- <div class="w3-container w3-light-grey w3-padding-32" id="talks">
    <h2>Talks</h2>
      <p><li> 12/2022, Hardware Efficient Deep Learning at <a href="https://ccf.org.cn/cncc2022/schedule_d_4179">China National Computer Congress (CNCC) 2022</a>. Thanks Prof. <a href="http://www.nlpr.ia.ac.cn/jcheng/">Jian Cheng</a> for the invitation.</li></p>
      <p><li> 05/2022, Low-Level Vision Transformer and Model Compression at <a href="https://2022.baai.ac.cn/">BAAI Conference 2022</a>. Thanks Prof. <a href="https://people.ucas.edu.cn/~sgshan?language=en">Shiguang Shan</a> for the invitation.</li></p>
      <p><li> 10/2021, Vision Transformer at <a href="http://valser.org/2021/#/tutorial">VALSE 2021 Tutorial</a>. Thanks Prof. <a href="https://people.ucas.edu.cn/~sgshan?language=en">Shiguang Shan</a> for the invitation.</li></p>
	  <p><li> 05/2021, Adder Neural Network at <a href="https://haet2021.github.io/speakers.html">HAET ICLR 2021 workshop</a>. Thanks <a href="https://datawisdom.ca/">Vahid Partovi Nia</a> for the invitation.</li></p>
      <p><li> 06/2020, "<a href="http://valser.org/webinar/slide/slides/20200603/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9-%E5%B7%A5%E4%B8%9A%E7%95%8C%E5%92%8C%E5%AD%A6%E6%9C%AF%E7%95%8C%E7%9A%84%E5%B7%AE%E5%BC%82.pdf">AI on the Edge - Discussion on the Gap Between Industry and Academia</a>" at <a  href="http://valser.org/">VALSE Webinar.</li>
      <p><li> 05/2020, "<a href="https://www.bilibili.com/video/av925692420/">Edge AI: Progress and Future Directions</a>" at <a href="https://www.qbitai.com/">QbitAI</a>.</li></p>
  </div> -->


 <!-- The Publications Section -->
  <div class="w3-container w3-padding-32"" id="publications">
    <h2>Research</h2>
      <!-- <p class="w3-left-align" style="line-height:200%">
        I'm interested in devleoping <strong>efficient models</strong> for computer vision 
        (e.g. classification, detection, and super-resolution) using pruning, quantization, distilaltion, NAS, etc. 
      </p> -->
    <h4> Conference Papers:</h4>

    <ol>
      <p>
      <li><strong>Active Universal Domain Adaptation</strong>
      <br>
      <strong>Xinhong Ma</strong>, Junyu Gao, Changsheng Xu
      <br>
      <em>ICCV</em> 2021 | 
      <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Ma_Active_Universal_Domain_Adaptation_ICCV_2021_paper.pdf">Paper</a> 
      <a style="color: #447ec9" href="https://openaccess.thecvf.com/content/ICCV2021/supplemental/Ma_Active_Universal_Domain_ICCV_2021_supplemental.pdf">Supp</a> 
      </p>

      <p>
        <li><strong>GCAN: Graph Convolutional Adversarial Network for Unsupervised Domain Adaptation</strong>
        <br>
        <strong>Xinhong Ma</strong>, Tianzhu Zhang, Changsheng Xu
        <br>
        <em>CVPR</em> 2019 | 
        <a style="color: #447ec9" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Ma_GCAN_Graph_Convolutional_Adversarial_Network_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.pdf">Paper</a> 
        <a style="color: #447ec9" href="https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Ma_GCAN_Graph_Convolutional_CVPR_2019_supplemental.pdf">Supp</a> 
      </p>
    </ol>

    <h4> Journal Papers:</h4>

    <ol>
      <p>
        <li><strong>The Model May Fit You: User-Generalized Cross-modal Retrieval</strong>
        <br>
        <strong>Xinhong Ma</strong>, Xiaoshan Yang, Junyu Gao, Changsheng Xu
        <br>
        <em>IEEE TMM</em> 2021 | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/abstract/document/9465686">Paper</a>
      </p>

      <p>
        <li><strong>Multi-Level Correlation Adversarial Hashing for Cross-Modal Retrieval</strong>
        <br>
        <strong>Xinhong Ma</strong>, Tianzhu Zhang, Changsheng Xu
        <br>
        <em>IEEE TMM</em> 2020 | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/abstract/document/8970562">Paper</a>
      </p>

      <p>
        <li><strong>Deep Multi-Modality Adversarial Networks for Unsupervised Domain Adaptation</strong>
        <br>
        <strong>Xinhong Ma</strong>, Tianzhu Zhang, Changsheng Xu
        <br>
        <em>IEEE TMM</em> 2019 | <a style="color: #447ec9" href="https://ieeexplore.ieee.org/abstract/document/8656504">Paper</a>
      </p>

    </ol>

  </div>

<!-- The Services Section -->
  <div class="w3-container w3-light-grey w3-padding-32" id="service">
    <h2>Services</h2>
      <p><li> Journal Reviewers of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE TPAMI</a>, 
        <!-- <a href="https://www.springer.com/journal/11263">IJCV</a>,  -->
        <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE TIP</a>,
         <!-- <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE T-NNLS</a>,  -->
        <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE TMM</a>, 
        <a href="https://dl.acm.org/journal/tomm">ACM TOMM</a>, etc.</p>
  </div>

  <!-- The Awards Section -->
  <div class="w3-container w3-padding-32" id="award">
    <h2>Awards</h2>
    <p><li> 2021, National Scholarship for Graduate Students.</p>
  </div>  

  <div class="w3-light-grey w3-center w3-padding-24">
    <!-- Welcome to use this website's <a href="https://github.com/YunheWang/HomePage">source code</a>, just add a link back to here. <a href="https://www.wangyunhe.site/">&#10025;</a>.</br>
     <a style="color:red">Note: If you use this template, please remove the following code or replace it with your own counter!</a>.</br> -->
			 
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-9P21LZSVW4"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-9P21LZSVW4');
	</script>
     
  </div>

  <!-- End page content -->
</div>

<script>
// Accordion 
function myAccFunc() {
  var x = document.getElementById("demoAcc");
  if (x.className.indexOf("w3-show") == -1) {
    x.className += " w3-show";
  } else {
    x.className = x.className.replace(" w3-show", "");
  }
}

// Click on the "Jeans" link on page load to open the accordion for demo purposes
document.getElementById("myBtn").click();


// Open and close sidebar
function w3_open() {
  document.getElementById("mySidebar").style.display = "block";
  document.getElementById("myOverlay").style.display = "block";
}
 
function w3_close() {
  document.getElementById("mySidebar").style.display = "none";
  document.getElementById("myOverlay").style.display = "none";
}
</script>

</body>
</html>
